# Probability

Probability is the likelihood of an event occuring. An event is a specific outcome or a combination of several outcomes - which could be pretty much anything. An example is when flipping a fair coin, we have two possible outcomes: head or tails thus we will assign two probabilities for both events.


Probabilities are often expressed as values between 0 and 1 where:

- A probability of `0` implies absolute certainty of the event `NOT` occuring
- A probability of `1` implies absolute certainty of the event occuring

## Definition

- `A` -> An event
- `P(A)` -> Probability of event A occuring is expressed as;

  - `P(A) = preferred outcomes / all outcomes`

This kind of probability is referred to as `theoretical (true)` probability

### Note

If two events are `independent` then:

`P(A and B) = P(A).P(B)`

An `independent` event is an event whose occurence is not dependent on any other. For example, if we flip a coin in the air and get the outcome as Head, then again if we flip the coin but this time we get the outcome as Tail. In both cases, the occurrence of both events is independent of each other.

## Expected Values

The average outcome we expect of we run an experiment many times.

- What is an `experiment`? Imagine we don't know what the probability of flipping a coin is. So we decide to estimate this probability ourselves.

    - `trial` -> flip and record outcome
    - `multiple trials` -> experiment

The probability we get after conducting experiments are called `experimental probabilities`

### Experimental Probability Definition

    - `P(A) = successful trials / all trials`